var relearn_searchindex = [
  {
    "breadcrumb": "",
    "content": "System modelling based on conventional mathematical tools (e.g., differential equations) is not well suited for dealing with ill-defined and uncertain systems. By contrast, a fuzzy inference system employing fuzzy if-then rules can model the qualitative aspects of human knowledge and reason- ing processes without employing precise quantitative analyses. This fuzzy modeling or fuzzy identification, first explored systematically by Takagi and Sugeno, has found numerous practical applications in control prediction and inference. However, there are some basic aspects of this approach which are in need of better understanding. More specifically:\nNo standard methods exist for transforming human knowledge or experience into the rule base and database of a fuzzy inference system. There is a need for effective methods for tuning the membership functions (MF’s) so as to minimize the output error measure or maximize performance index. In this perspective, the aim of this library is to suggest a novel architecture called Adaptive-Network-based Fuzzy Inference System, or simply ANFIS, which can serve as a basis for constructing a set of fuzzy if-then rules with appropriate membership functions to generate the stipulated input-output pairs.\nInput parameters The parameters can be stored as as a json with all the parameters or as 3 different jsons, storing: antecedent parameters, rules parameters, consequent parameters.\nAntecedents This will be the first layer of an ANFIS. Every $node_i$ in this layer is a square node with a node function\n$$O_{i}^{1}=\\mu_{A_{i}}(x)$$\nwhere $x$ is the input to $node_i$ , and A, is the linguistic label (small , large, etc.) associated with this node function. In other words, $O_{i}^{1}$ is the membership function of $A_{i}$ and it specifies the degree to which the given $x$ satisfies the quantifier $A_{i}$. Parameters in this layer are referred to as premise parameters.\nRules This is the second layer of an ANFIS, where fuzzy if-then rules are applied. Every node in this layer is a circle node labeled $\\prod$, which multiplies the incoming signals and sends the product out. Each node represents a single rule’s firing strength.\nNormalisation This will be the third layer of an ANFIS. Every node in this layer is a circle node labeled $N$. The ith node calculates the ratio of the ith rule’s firing strength to the sum of all rules’ firing strengths:\n$$O^{3} = \\frac{w_{i}}{\\sum {w_{i}}}$$\nConsequents This is the fourth layer of an ANFIS. Each node in this layer is a square node that computes the contribution of each rule to the overall output.\nOutput This is the fifth and final layer of an ANFIS. Each node in this layer is a circle node labeled $\\Sigma$ that computes the overall output as the summation of all incoming signals:\n$$O^{5}=\\sum_{i} \\overline{w_{i}} \\cdot f_i$$",
    "description": "System modelling based on conventional mathematical tools (e.g., differential equations) is not well suited for dealing with ill-defined and uncertain systems. By contrast, a fuzzy inference system employing fuzzy if-then rules can model the qualitative aspects of human knowledge and reason- ing processes without employing precise quantitative analyses. This fuzzy modeling or fuzzy identification, first explored systematically by Takagi and Sugeno, has found numerous practical applications in control prediction and inference. However, there are some basic aspects of this approach which are in need of better understanding. More specifically:",
    "tags": [],
    "title": "ANFIS",
    "uri": "/index.html"
  },
  {
    "breadcrumb": "ANFIS \u003e Documentation",
    "content": "CLASS pyanfis.antecedents.Antecedents(universes) Parameters The antecedents will receive a dictionary that inside will have a set of universes,\nname(dict) - dictionary with “Input 1”, “Input 2”, … as keys and universes as values. This class is used to define the range in which a variable is going to be defined in a fuzzy way, it is composed of several functions used to describe it.\nExample import torch from pyanfis.antecedents import Antecedents params = { \"Input 1\":{ \"name\": \"Dummy_Universe_1\", \"range\": (0, 3), \"functions\": { \"Small\": { \"type\": \"LinearZ\", \"parameters\": { \"shoulder\": 0, \"foot\": 2 } }, \"Medium\": { \"type\": \"Gauss\", \"parameters\": { \"mean\": 1.5, \"std\": 1 } }, \"Big\": { \"type\": \"LinearS\", \"parameters\": { \"foot\": 1, \"shoulder\": 3 } } } }, \"Input 2\":{ \"name\": \"Dummy_Universe_2\", \"range\": (0, 6), \"functions\": { \"Small\": { \"type\": \"LinearZ\", \"parameters\": { \"shoulder\": 0, \"foot\": 4 } }, \"Medium\": { \"type\": \"Gauss\", \"parameters\": { \"mean\": 3, \"std\": 2 } }, \"Big\": { \"type\": \"LinearS\", \"parameters\": { \"foot\": 2, \"shoulder\": 5 } } } } } antecedents = Antecedents(params) x_1 = torch.linspace(0, 3, 9).unsqueeze(0).unsqueeze(-1) x_2 = torch.linspace(0, 6, 9).unsqueeze(0).unsqueeze(-1) x = torch.cat((x_1, x_2), dim=2) f_x = antecedents(x) tensor([[[0.0000, 0.0000], [0.3750, 0.7500], [0.7500, 1.5000], [1.1250, 2.2500], [1.5000, 3.0000], [1.8750, 3.7500], [2.2500, 4.5000], [2.6250, 5.2500], [3.0000, 6.0000]]]) tensor([[[1.0000, 0.3247, 0.0000, 1.0000, 0.3247, 0.0000], [0.8125, 0.5311, 0.0000, 0.8125, 0.5311, 0.0000], [0.6250, 0.7548, 0.0000, 0.6250, 0.7548, 0.0000], [0.4375, 0.9321, 0.0625, 0.4375, 0.9321, 0.0833], [0.2500, 1.0000, 0.2500, 0.2500, 1.0000, 0.3333], [0.0625, 0.9321, 0.4375, 0.0625, 0.9321, 0.5833], [0.0000, 0.7548, 0.6250, 0.0000, 0.7548, 0.8333], [0.0000, 0.5311, 0.8125, 0.0000, 0.5311, 1.0000], [0.0000, 0.3247, 1.0000, 0.0000, 0.3247, 1.0000]]], grad_fn=\u003cIndexPutBackward0\u003e) Visualization import matplotlib.pyplot as plt fig, axs = plt.subplots(nrows=1, ncols=len(antecedents.universes), figsize=(15, 5)) axs = axs.flatten() for ax, (universe, i) in zip(axs, zip(antecedents.universes.values(), x.T)): ax.set_title(universe.name) ax.set_xlabel(\"x\") ax.set_ylabel(\"f (x)\") ax.margins(y=0.05) i = i.unsqueeze(0) ax.plot(i[0, :, :].detach(), universe(i)[0, :, :].detach()) plt.tight_layout() plt.show()",
    "description": "CLASS pyanfis.antecedents.Antecedents(universes) Parameters The antecedents will receive a dictionary that inside will have a set of universes,\nname(dict) - dictionary with “Input 1”, “Input 2”, … as keys and universes as values. This class is used to define the range in which a variable is going to be defined in a fuzzy way, it is composed of several functions used to describe it.\nExample import torch from pyanfis.antecedents import Antecedents params = { \"Input 1\":{ \"name\": \"Dummy_Universe_1\", \"range\": (0, 3), \"functions\": { \"Small\": { \"type\": \"LinearZ\", \"parameters\": { \"shoulder\": 0, \"foot\": 2 } }, \"Medium\": { \"type\": \"Gauss\", \"parameters\": { \"mean\": 1.5, \"std\": 1 } }, \"Big\": { \"type\": \"LinearS\", \"parameters\": { \"foot\": 1, \"shoulder\": 3 } } } }, \"Input 2\":{ \"name\": \"Dummy_Universe_2\", \"range\": (0, 6), \"functions\": { \"Small\": { \"type\": \"LinearZ\", \"parameters\": { \"shoulder\": 0, \"foot\": 4 } }, \"Medium\": { \"type\": \"Gauss\", \"parameters\": { \"mean\": 3, \"std\": 2 } }, \"Big\": { \"type\": \"LinearS\", \"parameters\": { \"foot\": 2, \"shoulder\": 5 } } } } } antecedents = Antecedents(params) x_1 = torch.linspace(0, 3, 9).unsqueeze(0).unsqueeze(-1) x_2 = torch.linspace(0, 6, 9).unsqueeze(0).unsqueeze(-1) x = torch.cat((x_1, x_2), dim=2) f_x = antecedents(x) tensor([[[0.0000, 0.0000], [0.3750, 0.7500], [0.7500, 1.5000], [1.1250, 2.2500], [1.5000, 3.0000], [1.8750, 3.7500], [2.2500, 4.5000], [2.6250, 5.2500], [3.0000, 6.0000]]]) tensor([[[1.0000, 0.3247, 0.0000, 1.0000, 0.3247, 0.0000], [0.8125, 0.5311, 0.0000, 0.8125, 0.5311, 0.0000], [0.6250, 0.7548, 0.0000, 0.6250, 0.7548, 0.0000], [0.4375, 0.9321, 0.0625, 0.4375, 0.9321, 0.0833], [0.2500, 1.0000, 0.2500, 0.2500, 1.0000, 0.3333], [0.0625, 0.9321, 0.4375, 0.0625, 0.9321, 0.5833], [0.0000, 0.7548, 0.6250, 0.0000, 0.7548, 0.8333], [0.0000, 0.5311, 0.8125, 0.0000, 0.5311, 1.0000], [0.0000, 0.3247, 1.0000, 0.0000, 0.3247, 1.0000]]], grad_fn=\u003cIndexPutBackward0\u003e) Visualization import matplotlib.pyplot as plt fig, axs = plt.subplots(nrows=1, ncols=len(antecedents.universes), figsize=(15, 5)) axs = axs.flatten() for ax, (universe, i) in zip(axs, zip(antecedents.universes.values(), x.T)): ax.set_title(universe.name) ax.set_xlabel(\"x\") ax.set_ylabel(\"f (x)\") ax.margins(y=0.05) i = i.unsqueeze(0) ax.plot(i[0, :, :].detach(), universe(i)[0, :, :].detach()) plt.tight_layout() plt.show()",
    "tags": [],
    "title": "Antecedents",
    "uri": "/documentation/antecedents/index.html"
  },
  {
    "breadcrumb": "ANFIS \u003e Documentation",
    "content": "This is a new chapter.",
    "description": "This is a new chapter.",
    "tags": [],
    "title": "Consequents",
    "uri": "/documentation/consequents/index.html"
  },
  {
    "breadcrumb": "ANFIS",
    "content": "System modelling based on conventional mathematical tools (e.g., differential equations) is not well suited for dealing with ill-defined and uncertain systems. By contrast, a fuzzy inference system employing fuzzy if-then rules can model the qualitative aspects of human knowledge and reason- ing processes without employing precise quantitative analyses. This fuzzy modeling or fuzzy identification, first explored systematically by Takagi and Sugeno, has found numerous practical applications in control prediction and inference. However, there are some basic aspects of this approach which are in need of better understanding. More specifically:\nNo standard methods exist for transforming human knowledge or experience into the rule base and database of a fuzzy inference system. There is a need for effective methods for tuning the membership functions (MF’s) so as to minimize the output error measure or maximize performance index. In this perspective, the aim of this library is to suggest a novel architecture called Adaptive-Network-based Fuzzy Inference System, or simply ANFIS, which can serve as a basis for constructing a set of fuzzy if-then rules with appropriate membership functions to generate the stipulated input-output pairs.\nInput parameters The parameters can be stored as as a json with all the parameters or as 3 different jsons, storing: antecedent parameters, rules parameters, consequent parameters.\nAntecedents This will be the first layer of an ANFIS. Every $node_i$ in this layer is a square node with a node function\n$$O_{i}^{1}=\\mu_{A_{i}}(x)$$\nwhere $x$ is the input to $node_i$ , and A, is the linguistic label (small , large, etc.) associated with this node function. In other words, $O_{i}^{1}$ is the membership function of $A_{i}$ and it specifies the degree to which the given $x$ satisfies the quantifier $A_{i}$. Parameters in this layer are referred to as premise parameters.\nRules This is the second layer of an ANFIS, where fuzzy if-then rules are applied. Every node in this layer is a circle node labeled $\\prod$, which multiplies the incoming signals and sends the product out. Each node represents a single rule’s firing strength.\nNormalisation This will be the third layer of an ANFIS. Every node in this layer is a circle node labeled $N$. The ith node calculates the ratio of the ith rule’s firing strength to the sum of all rules’ firing strengths:\n$$O^{3} = \\frac{w_{i}}{\\sum {w_{i}}}$$\nConsequents This is the fourth layer of an ANFIS. Each node in this layer is a square node that computes the contribution of each rule to the overall output.\nOutput This is the fifth and final layer of an ANFIS. Each node in this layer is a circle node labeled $\\Sigma$ that computes the overall output as the summation of all incoming signals:\n$$O^{5}=\\sum_{i} \\overline{w_{i}} \\cdot f_i$$",
    "description": "System modelling based on conventional mathematical tools (e.g., differential equations) is not well suited for dealing with ill-defined and uncertain systems. By contrast, a fuzzy inference system employing fuzzy if-then rules can model the qualitative aspects of human knowledge and reason- ing processes without employing precise quantitative analyses. This fuzzy modeling or fuzzy identification, first explored systematically by Takagi and Sugeno, has found numerous practical applications in control prediction and inference. However, there are some basic aspects of this approach which are in need of better understanding. More specifically:",
    "tags": [],
    "title": "Documentation",
    "uri": "/documentation/index.html"
  },
  {
    "breadcrumb": "ANFIS \u003e Documentation",
    "content": "This is a new chapter.",
    "description": "This is a new chapter.",
    "tags": [],
    "title": "Examples",
    "uri": "/documentation/examples/index.html"
  },
  {
    "breadcrumb": "ANFIS \u003e Documentation",
    "content": "The model will need a certain kind of parameters to be able to run properly. The system will accept three main parameters: antecedents, rules and consequents. The system will accept accept a big quantity of parameters, so it is advised to store the parameters on a different json. In the following subsections it will be exposed the structure of each main parameter group.\nAntecedents The antecedents json will contain all the information related to the universes present in the antecedents. Each main key in this dictionary will be used to indicate which input is being used (Input 1, 2, 3, ….). Each value related to a key will contain a dictionary with:\nA name for the universe. A range for the universe (in the form of a list, that goes from min to max). dictionary with { \"Input 1\": { \"name\": \"Num_1\", \"range\": [0, 10], \"functions\": { \"Small\": { \"type\": \"LinearZ\", \"parameters\": { \"foot\": 10, \"shoulder\": 0 } }, \"Big\": { \"type\": \"LinearS\", \"parameters\": { \"shoulder\": 10, \"foot\": 0 } } } } }",
    "description": "The model will need a certain kind of parameters to be able to run properly. The system will accept three main parameters: antecedents, rules and consequents. The system will accept accept a big quantity of parameters, so it is advised to store the parameters on a different json. In the following subsections it will be exposed the structure of each main parameter group.\nAntecedents The antecedents json will contain all the information related to the universes present in the antecedents. Each main key in this dictionary will be used to indicate which input is being used (Input 1, 2, 3, ….). Each value related to a key will contain a dictionary with:",
    "tags": [],
    "title": "Input parameters",
    "uri": "/documentation/input_parameters/index.html"
  },
  {
    "breadcrumb": "ANFIS \u003e Documentation \u003e Consequents",
    "content": "",
    "description": "",
    "tags": [],
    "title": "Mamdani",
    "uri": "/documentation/consequents/mamdani/index.html"
  },
  {
    "breadcrumb": "ANFIS \u003e Documentation \u003e Consequents",
    "content": "The Takagi-Sugeno Fuzzy Model also known as Adaptive Neuro-Fuzzy Inference Systems (ANFIS) is a Type 3 Fuzzy Inference System, where the final output is the weighted average of the outputs of all the rules and the rule outputs are a linear combination of the input variables and a constant. The following is a description of the IF-THEN rules for a Takagi-Sugeno system with three inputs:\nRule 1: IF ..., THEN f1 = p1 x + q1 y + r1z + s1. Rule 2: IF ...,THEN f2 = p2 x + q2 y + r2z + s2. Rule 3: IF ..., THEN f3 = p3 x + q3 y + r3z + s3. Where, the inputs in the crisp set are denoted by ×,y, z (as mentioned in Table 6); linguistic labels by Ai, Bi, Ci; consequent parameters by pi, qi, ri and the output fuzzy membership functions by f1, f2, f3. Five layers of linked neurons make up the typical ANFIS design, as shown in Fig. 9, which is indicative of artificial neural networks with similar functionality. In the Fig. 9, w1,w2 and w3 represents the weights of the neurons and , and represents the normalized weights of the neurons (Chopra et al., 2021).",
    "description": "The Takagi-Sugeno Fuzzy Model also known as Adaptive Neuro-Fuzzy Inference Systems (ANFIS) is a Type 3 Fuzzy Inference System, where the final output is the weighted average of the outputs of all the rules and the rule outputs are a linear combination of the input variables and a constant. The following is a description of the IF-THEN rules for a Takagi-Sugeno system with three inputs:\nRule 1: IF ..., THEN f1 = p1 x + q1 y + r1z + s1. Rule 2: IF ...,THEN f2 = p2 x + q2 y + r2z + s2. Rule 3: IF ..., THEN f3 = p3 x + q3 y + r3z + s3. Where, the inputs in the crisp set are denoted by ×,y, z (as mentioned in Table 6); linguistic labels by Ai, Bi, Ci; consequent parameters by pi, qi, ri and the output fuzzy membership functions by f1, f2, f3. Five layers of linked neurons make up the typical ANFIS design, as shown in Fig. 9, which is indicative of artificial neural networks with similar functionality. In the Fig. 9, w1,w2 and w3 represents the weights of the neurons and , and represents the normalized weights of the neurons (Chopra et al., 2021).",
    "tags": [],
    "title": "Takagi-Sugeno",
    "uri": "/documentation/consequents/ts/index.html"
  },
  {
    "breadcrumb": "ANFIS \u003e Documentation \u003e Examples",
    "content": "In this example you will learn how to reproduce the original example of Jang’s paper on how to forecast chaotic time series.\nImports First step is to get the necessary imports, in this case we will import PyTorch and pyANFIS.\nimport json import torch from pyanfis import ANFIS Parameters of the ANFIS The following json will contain all the parameters of the ANFIS. This new way of adding information to the system is explained in here.\n{ \"antecedents\": { \"Input 1\": { \"name\": \"x(t)\", \"range\": [0, 2], \"functions\": { \"Small\": { \"type\": \"Gauss\", \"parameters\": { \"mean\": 0.5, \"std\": 0.5 } }, \"Big\": { \"type\": \"Gauss\", \"parameters\": { \"mean\": 1.5, \"std\": 0.5 } } } }, \"Input 2\": { \"name\": \"x(t-6)\", \"range\": [0, 2], \"functions\": { \"Small\": { \"type\": \"Gauss\", \"parameters\": { \"mean\": 0.5, \"std\": 0.5 } }, \"Big\": { \"type\": \"Gauss\", \"parameters\": { \"mean\": 1.5, \"std\": 0.5 } } } }, \"Input 3\": { \"name\": \"x(t-12)\", \"range\": [0, 2], \"functions\": { \"Small\": { \"type\": \"Gauss\", \"parameters\": { \"mean\": 0.5, \"std\": 0.5 } }, \"Big\": { \"type\": \"Gauss\", \"parameters\": { \"mean\": 1.5, \"std\": 0.5 } } } }, \"Input 4\": { \"name\": \"x(t-18)\", \"range\": [0, 2], \"functions\": { \"Small\": { \"type\": \"Gauss\", \"parameters\": { \"mean\": 0.5, \"std\": 0.5 } }, \"Big\": { \"type\": \"Gauss\", \"parameters\": { \"mean\": 1.5, \"std\": 0.5 } } } } }, \"rules\": { \"intersection\": \"larsen\", \"rules_base\": [ \"If x(t-18) is Small and x(t-12) is Small and x(t-6) is Small and x(t) is Small then x(t+6) is ...\", \"If x(t-18) is Small and x(t-12) is Small and x(t-6) is Small and x(t) is Big then x(t+6) is ...\", \"If x(t-18) is Small and x(t-12) is Small and x(t-6) is Big and x(t) is Small then x(t+6) is ...\", \"If x(t-18) is Small and x(t-12) is Small and x(t-6) is Big and x(t) is Big then x(t+6) is ...\", \"If x(t-18) is Small and x(t-12) is Big and x(t-6)is Small and x(t) is Small then x(t+6) is ...\", \"If x(t-18) is Small and x(t-12) is Big and x(t-6) is Small and x(t) is Big then x(t+6) is ...\", \"If x(t-18) is Small and x(t-12) is Big and x(t-6) is Big and x(t) is Small then x(t+6) is ...\", \"If x(t-18) is Small and x(t-12) is Big and x(t-6) is Big and x(t) is Big then x(t+6) is ...\", \"If x(t-18) is Big and x(t-12) is Small and x(t-6) is Small and x(t) is Small then x(t+6) is ...\", \"If x(t-18) is Big and x(t-12) is Small and x(t-6) is Small and x(t) is Big then x(t+6) is ...\", \"If x(t-18) is Big and x(t-12) is Small and x(t-6) is Big and x(t) is Small then x(t+6) is ...\", \"If x(t-18) is Big and x(t-12) is Small and x(t-6) is Big and x(t) is Big then x(t+6) is ...\", \"If x(t-18) is Big and x(t-12) is Big and x(t-6) is Small and x(t) is Small then x(t+6) is ...\", \"If x(t-18) is Big and x(t-12) is Big and x(t-6) is Small and x(t) is Big then x(t+6) is ...\", \"If x(t-18) is Big and x(t-12) is Big and x(t-6) is Big and x(t) is Small then x(t+6) is ...\", \"If x(t-18) is Big and x(t-12) is Big and x(t-6) is Big and x(t) is Big then x(t+6) is ...\" ] }, \"consequents\": { \"Output 1\": { \"type\": \"Takagi-Sugeno\", \"name\": \"x(t+6)\", \"parameters\":{ \"parameters_update\": \"forward\", \"algorithm\": \"RLSE\" } } } } To import the data that is about to be loaded into the model, you just need to open the previous json using:\nwith open('data.json', 'r') as f: data = json.load(f) And to load the data into the model:\nmodel = ANFIS(**data) # Remember to put the two asterisks in front of the data that is about to get imported Creating the training data The training data will be generated by the chaotic Mackey-Glass differential delay equation:\n$$ \\dot{x}(t) = 0.2 \\cdot \\frac{x(t - \\tau)}{1 + x(t - \\tau)^{10}} - 0.1 \\cdot x(t) $$\nusing the following code:\nts = 1 numSamples = 1200 tau = 20 x = torch.zeros(numSamples + tau + 1) x[tau] = 1.2 for t in range(tau, numSamples + tau): x_dot = 0.2 * x[t - tau] / (1 + (x[t - tau])**10) - 0.1 * x[t] x[t + 1] = x[t] + ts * x_dot Optimizers To compute the backpropagation update for the antecedent functions, you will need to call model.parameters() and pass the parameters to an optimizer, in our case it’s an Adam optimizer. After this, we will initialise the way in which we will compute the loss, in our case the MSELoss.\nmodel_optimizer = torch.optim.Adam(model.parameters(), lr=0.00001) mse_loss = torch.nn.MSELoss() \u003cbr Remember that if you look at the json containing the data, the consequents will be updated in the forward propagation.\nTraining loop The training loop will look as a normal training loop of PyTorch.\nCaution If you are using for the input variables names with: spaces, parenthesis or variable names that would not be allowed for python, you will need to input the data as a dictionary, as shown in the example.\nn_epochs = 300 epoch_loss = 0 for epoch in range(0, n_epochs): for i in range(18, len(x)-6): model_inputs = { \"x(t-18)\": x[i-18], \"x(t-12)\": x[i-12], \"x(t-6)\": x[i-6], \"x(t)\": x[i], \"x(t+6)\": x[i+6] } output = model(**model_inputs) model_loss = mse_loss(output, x[i+6]) model_loss.backward() model_optimizer.step() epoch_loss += model_loss epoch_loss = epoch_loss/i print(f\"Epoch {epoch} mean loss is {epoch_loss}\") if epoch_loss \u003c 0.01: print(f\"Early stopping with loss equal to {epoch_loss}\") break epoch_loss = 0 Epoch 0 mean loss is 0.0005760298226960003 Early stopping with loss equal to 0.0005760298226960003 Evaluation of the model After training the model, it is time to evaluate its performance with data that it has never seen.\nmodel.eval() x_truth = x[18:len(x)-6] x_test = [model(**{\"x(t-18)\": x[i-18], \"x(t-12)\": x[i-12], \"x(t-6)\": x[i-6],\"x(t)\": x[i]}).item() for i in range(18, len(x)-6)] import matplotlib.pyplot as plt plt.plot(x_truth, label=\"Truth\") plt.plot(x_test, \"--\", label=\"Forecast\") plt.legend() plt.show()",
    "description": "In this example you will learn how to reproduce the original example of Jang’s paper on how to forecast chaotic time series.\nImports First step is to get the necessary imports, in this case we will import PyTorch and pyANFIS.\nimport json import torch from pyanfis import ANFIS Parameters of the ANFIS The following json will contain all the parameters of the ANFIS. This new way of adding information to the system is explained in here.",
    "tags": [],
    "title": "Time series forecasting",
    "uri": "/documentation/examples/mamdani/index.html"
  },
  {
    "breadcrumb": "ANFIS \u003e Documentation",
    "content": "This is a new chapter.",
    "description": "This is a new chapter.",
    "tags": [],
    "title": "Algorithms",
    "uri": "/documentation/algorithms/index.html"
  },
  {
    "breadcrumb": "ANFIS \u003e Documentation",
    "content": "This is a new chapter.",
    "description": "This is a new chapter.",
    "tags": [],
    "title": "Rules",
    "uri": "/documentation/rules/index.html"
  },
  {
    "breadcrumb": "ANFIS",
    "content": "",
    "description": "",
    "tags": [],
    "title": "Blog",
    "uri": "/blog/index.html"
  },
  {
    "breadcrumb": "ANFIS \u003e Documentation \u003e Functions",
    "content": "CLASS pyanfis.functions.Bell(width, shape, center) Parameters name type description width int, float width of the bell function shape int, float shape of the transition area of the bell function center int, float center of the bell function Example The first step is to import torch and the function using:\nimport torch from pyanfis.functions import Bell After importing the function, we will initialise it with a width value of 1, a shape value of 0.5 and a center value of 1.5:\nbell = Bell(width = 1, shape = 0.5, center = 1.5) x = torch.linspace(0, 3, 9) f_x = bell(x) The input tensor x will be:\ntensor([0.0000, 0.3750, 0.7500, 1.1250, 1.5000, 1.8750, 2.2500, 2.6250, 3.0000]) And the output tensor f_x will be:\ntensor([0.4000, 0.4706, 0.5714, 0.7273, 1.0000, 0.7273, 0.5714, 0.4706, 0.4000], grad_fn=\u003cMulBackward0\u003e) Visualisation To visualize a function we will import the function and the matplotlib module:\nimport matplotlib.pyplot as plt import torch from pyanfis.functions import Bell Before plotting it, we will need the x values given by x and the y value given by f_x:\nbell = Bell(width = 1, shape = 0.5, center = 1.5) x = torch.linspace(0, 3, 9) f_x = bell(x) To plot the image use:\nplt.style.use(\"classic\") plt.title(\"Bell\") plt.xlabel(\"x\") plt.ylabel(\"f (x)\") plt.margins(y=0.05) plt.plot(x.detach(), f_x.detach()) plt.show() And the final plotted function will be:",
    "description": "CLASS pyanfis.functions.Bell(width, shape, center) Parameters name type description width int, float width of the bell function shape int, float shape of the transition area of the bell function center int, float center of the bell function Example The first step is to import torch and the function using:\nimport torch from pyanfis.functions import Bell After importing the function, we will initialise it with a width value of 1, a shape value of 0.5 and a center value of 1.5:",
    "tags": [],
    "title": "Bell",
    "uri": "/documentation/functions/bell/index.html"
  },
  {
    "breadcrumb": "ANFIS \u003e Documentation",
    "content": "Classical logic only permits conclusions that are either true or false. However, there are also propositions with variable answers, which one might find when asking a group of people to identify a color. In such instances, the truth appears as the result of reasoning from inexact or partial knowledge in which the sampled answers are mapped on a spectrum.\nBoth degrees of truth and probabilities range between 0 and 1 and hence may seem identical at first, but fuzzy logic uses degrees of truth as a mathematical model of vagueness, while probability is a mathematical model of ignorance. In this context, functions are used to transform a CRISP number into a degree of truth.",
    "description": "Classical logic only permits conclusions that are either true or false. However, there are also propositions with variable answers, which one might find when asking a group of people to identify a color. In such instances, the truth appears as the result of reasoning from inexact or partial knowledge in which the sampled answers are mapped on a spectrum.\nBoth degrees of truth and probabilities range between 0 and 1 and hence may seem identical at first, but fuzzy logic uses degrees of truth as a mathematical model of vagueness, while probability is a mathematical model of ignorance. In this context, functions are used to transform a CRISP number into a degree of truth.",
    "tags": [],
    "title": "Functions",
    "uri": "/documentation/functions/index.html"
  },
  {
    "breadcrumb": "ANFIS \u003e Documentation \u003e Functions",
    "content": "CLASS pyanfis.functions.Gauss(mean, std) Parameters name type description mean int, float mean of the gaussian function std int, float standard deviation of the gaussian function Example The first step is to import torch and the function using:\nimport torch from pyanfis.functions import Gauss After importing the function, we will initialise it with a mean value of 1.5 and a standard deviation value of 0.5:\ngauss = Gauss(mean = 1.5, std = 0.5) x = torch.linspace(0, 3, 9) f_x = gauss(x) The input tensor x will be:\ntensor([0.0000, 0.3750, 0.7500, 1.1250, 1.5000, 1.8750, 2.2500, 2.6250, 3.0000]) And the output tensor f_x will be:\ntensor([0.0111, 0.0796, 0.3247, 0.7548, 1.0000, 0.7548, 0.3247, 0.0796, 0.0111], grad_fn=\u003cExpBackward0\u003e) Visualisation To visualize a function we will import the function and the matplotlib module:\nimport matplotlib.pyplot as plt import torch from pyanfis.functions import Gauss Before plotting it, we will need the x values given by x and the y value given by f_x:\ngauss = Gauss(mean = 1.5, std = 0.5) x = torch.linspace(0, 3, 9) f_x = gauss(x) To plot the image use:\nplt.style.use(\"classic\") plt.title(\"Gauss\") plt.xlabel(\"x\") plt.ylabel(\"f (x)\") plt.margins(y=0.05) plt.plot(x.detach(), f_x.detach()) plt.show() And the final plotted function will be:",
    "description": "CLASS pyanfis.functions.Gauss(mean, std) Parameters name type description mean int, float mean of the gaussian function std int, float standard deviation of the gaussian function Example The first step is to import torch and the function using:\nimport torch from pyanfis.functions import Gauss After importing the function, we will initialise it with a mean value of 1.5 and a standard deviation value of 0.5:\ngauss = Gauss(mean = 1.5, std = 0.5) x = torch.linspace(0, 3, 9) f_x = gauss(x) The input tensor x will be:",
    "tags": [],
    "title": "Gauss",
    "uri": "/documentation/functions/gauss/index.html"
  },
  {
    "breadcrumb": "ANFIS \u003e Documentation \u003e Functions",
    "content": "CLASS pyanfis.functions.LinearS(foot, shoulder) Parameters name type description shoulder int, float position of the shoulder of the function foot int, float position of the foot of the function Example The first step is to import torch and the function using:\nimport torch from pyanfis.functions import LinearS After importing the function, we will initialise it with a foot value of 1 and a shoulder value of 2:\nlinear_s = LinearS(foot = 1, shoulder = 2) x = torch.linspace(0, 3, 9) f_x = linear_s(x) The input tensor x will be:\ntensor([0.0000, 0.3750, 0.7500, 1.1250, 1.5000, 1.8750, 2.2500, 2.6250, 3.0000]) And the output tensor f_x will be:\ntensor([0.0000, 0.0000, 0.0000, 0.1250, 0.5000, 0.8750, 1.0000, 1.0000, 1.0000], grad_fn=\u003cMinimumBackward0\u003e) Visualisation To visualize a function we will import the function and the matplotlib module:\nimport matplotlib.pyplot as plt import torch from pyanfis.functions import LinearS Before plotting it, we will need the x values given by x and the y value given by f_x:\nlinear_s = LinearS(foot = 1, shoulder = 2) x = torch.linspace(0, 3, 9) f_x = linear_s(x) To plot the image use:\nplt.style.use(\"classic\") plt.title(\"Linear S\") plt.xlabel(\"x\") plt.ylabel(\"f (x)\") plt.margins(y=0.05) plt.plot(x.detach(), f_x.detach()) plt.show() And the final plotted function will be:",
    "description": "CLASS pyanfis.functions.LinearS(foot, shoulder) Parameters name type description shoulder int, float position of the shoulder of the function foot int, float position of the foot of the function Example The first step is to import torch and the function using:\nimport torch from pyanfis.functions import LinearS After importing the function, we will initialise it with a foot value of 1 and a shoulder value of 2:\nlinear_s = LinearS(foot = 1, shoulder = 2) x = torch.linspace(0, 3, 9) f_x = linear_s(x) The input tensor x will be:",
    "tags": [],
    "title": "Linear S",
    "uri": "/documentation/functions/linear_s/index.html"
  },
  {
    "breadcrumb": "ANFIS \u003e Documentation \u003e Functions",
    "content": "CLASS pyanfis.functions.LinearZ(shoulder, foot) Parameters name type description shoulder int, float position of the shoulder of the function foot int, float position of the foot of the function Example The first step is to import torch and the function using:\nimport torch from pyanfis.functions import LinearZ After importing the function, we will initialise it with a shoulder value of 1 and a foot value of 2:\nlinear_z = LinearZ(shoulder = 1, foot = 2) x = torch.linspace(0, 3, 9) f_x = linear_z(x) The input tensor x will be:\ntensor([0.0000, 0.3750, 0.7500, 1.1250, 1.5000, 1.8750, 2.2500, 2.6250, 3.0000]) And the output tensor f_x will be:\ntensor([1.0000, 0.8750, 0.5000, 0.1250, 0.0000, 0.0000, 0.0000], grad_fn=\u003cMaximumBackward0\u003e) Visualisation To visualize a function we will import the function and the matplotlib module:\nimport matplotlib.pyplot as plt import torch from pyanfis.functions import LinearZ Before plotting it, we will need the x values given by x and the y value given by f_x:\nlinear_z = LinearZ(shoulder = 1, foot = 2) x = torch.linspace(0, 3, 9) f_x = linear_z(x) To plot the image use:\nplt.style.use(\"classic\") plt.title(\"Linear Z\") plt.xlabel(\"x\") plt.ylabel(\"f (x)\") plt.margins(y=0.05) plt.plot(x.detach(), f_x.detach()) plt.show() And the final plotted function will be:",
    "description": "CLASS pyanfis.functions.LinearZ(shoulder, foot) Parameters name type description shoulder int, float position of the shoulder of the function foot int, float position of the foot of the function Example The first step is to import torch and the function using:\nimport torch from pyanfis.functions import LinearZ After importing the function, we will initialise it with a shoulder value of 1 and a foot value of 2:\nlinear_z = LinearZ(shoulder = 1, foot = 2) x = torch.linspace(0, 3, 9) f_x = linear_z(x) The input tensor x will be:",
    "tags": [],
    "title": "Linear Z",
    "uri": "/documentation/functions/linear_z/index.html"
  },
  {
    "breadcrumb": "ANFIS \u003e Documentation \u003e Functions",
    "content": "CLASS pyanfis.functions.Sigmoid(width, center) Parameters name type description width int, float width of the transition area of the sigmoid function center int, float center of the sigmoid function Example The first step is to import torch and the function using:\nimport torch from pyanfis.functions import Sigmoid After importing the function, we will initialise it with a width value of 1 and a center value of 1:\nsigmoid = Sigmoid(width = 1, center = 1.5) x = torch.linspace(0, 3, 9) f_x = sigmoid(x) The input tensor x will be:\ntensor([0.0000, 0.3750, 0.7500, 1.1250, 1.5000, 1.8750, 2.2500, 2.6250, 3.0000]) And the output tensor f_x will be:\ntensor([0.1824, 0.2451, 0.3208, 0.4073, 0.5000, 0.5927, 0.6792, 0.7549, 0.8176], grad_fn=\u003cMulBackward0\u003e) Visualisation To visualize a function we will import the function and the matplotlib module:\nimport matplotlib.pyplot as plt import torch from pyanfis.functions import Sigmoid Before plotting it, we will need the x values given by x and the y value given by f_x:\nsigmoid = Sigmoid(width = 1, center = 1.5) x = torch.linspace(0, 3, 9) f_x = sigmoid(x) To plot the image use:\nplt.style.use(\"classic\") plt.title(\"Sigmoid\") plt.xlabel(\"x\") plt.ylabel(\"f (x)\") plt.margins(y=0.05) plt.plot(x.detach(), f_x.detach()) plt.show() And the final plotted function will be:",
    "description": "CLASS pyanfis.functions.Sigmoid(width, center) Parameters name type description width int, float width of the transition area of the sigmoid function center int, float center of the sigmoid function Example The first step is to import torch and the function using:\nimport torch from pyanfis.functions import Sigmoid After importing the function, we will initialise it with a width value of 1 and a center value of 1:\nsigmoid = Sigmoid(width = 1, center = 1.5) x = torch.linspace(0, 3, 9) f_x = sigmoid(x) The input tensor x will be:",
    "tags": [],
    "title": "Sigmoid",
    "uri": "/documentation/functions/sigmoid/index.html"
  },
  {
    "breadcrumb": "ANFIS \u003e Documentation \u003e Functions",
    "content": "CLASS pyanfis.functions.Triangular(left_foot, peak, right_foot) Parameters name type description left_foot int, float right place where the base of the triangular function will be located peak int, float place where the peak of the triangular function will be located right_foot int, float left place where the base of the triangular function will be located Example The first step is to import torch and the function using:\nimport torch from pyanfis.functions import Triangular After importing the function, we will initialise it with a left foot value of 1, a peak value of 2 and a right foot value of 3:\ntriangular = Triangular(left_foot = 1, peak = 2, right_foot = 3) x = torch.linspace(0, 3, 9) f_x = triangular(x) The input tensor x will be:\ntensor([0.0000, 0.3750, 0.7500, 1.1250, 1.5000, 1.8750, 2.2500, 2.6250, 3.0000]) And the output tensor f_x will be:\ntensor([0.0000, 0.0000, 0.0000, 0.1250, 0.5000, 0.8750, 0.7500, 0.3750, 0.0000], grad_fn=\u003cMaximumBackward0\u003e) Visualisation To visualize a function we will import the function and the matplotlib module:\nimport matplotlib.pyplot as plt import torch from pyanfis.functions import Gauss Before plotting it, we will need the x values given by x and the y value given by f_x:\ntriangular = Triangular(left_foot = 1, peak = 2, right_foot = 3) x = torch.linspace(0, 3, 9) f_x = triangular(x) To plot the image use:\nplt.style.use(\"classic\") plt.title(\"Triangular\") plt.xlabel(\"x\") plt.ylabel(\"f (x)\") plt.margins(y=0.05) plt.plot(x.detach(), f_x.detach()) plt.show() And the final plotted function will be:",
    "description": "CLASS pyanfis.functions.Triangular(left_foot, peak, right_foot) Parameters name type description left_foot int, float right place where the base of the triangular function will be located peak int, float place where the peak of the triangular function will be located right_foot int, float left place where the base of the triangular function will be located Example The first step is to import torch and the function using:\nimport torch from pyanfis.functions import Triangular After importing the function, we will initialise it with a left foot value of 1, a peak value of 2 and a right foot value of 3:",
    "tags": [],
    "title": "Triangular",
    "uri": "/documentation/functions/triangular/index.html"
  },
  {
    "breadcrumb": "ANFIS \u003e Documentation",
    "content": "CLASS pyanfis.functions.Universe(name, range, functions) Parameters name type description name str name of the universe range tuple range of the universe, from min to max where min \u003c max functions dict dict with names of functions and properties of functions In regards to the functions parameter, you should input a dictionary where each key is the name of the function and each value is a dict that indicates its type and and its parameters:\n{ \"Small\": { \"type\": \"LinearZ\", \"parameters\": { \"foot\": 10, \"shoulder\": 0 } }, \"Big\": { \"type\": \"LinearS\", \"parameters\": { \"shoulder\": 10, \"foot\": 0 } } } Example The first step is to import torch and the universe using:\nimport torch from pyanfis.functions import Universe A universe will accept: a name, a range where the universe will be evaluated and a dictionary of functions that will comprise the different linguistical variables. It is easier to embed all the parameters into a dictionary and feed them into the system:\nparams = { \"name\": \"Dummy_Universe\", \"range\": (0, 3), \"functions\": { \"Small\": { \"type\": \"LinearZ\", \"parameters\": { \"shoulder\": 0, \"foot\": 2 } }, \"Medium\": { \"type\": \"Gauss\", \"parameters\": { \"mean\": 1.5, \"std\": 1 } }, \"Big\": { \"type\": \"LinearS\", \"parameters\": { \"foot\": 1, \"shoulder\": 3 } } } } The parameters are passed to the universe using the two asterisks in front of the the dictionary:\nuniverse = Universe(**params) Incidentally, you can also pass the parameters into the universe as:\nuniverse = Universe( name = \"Dummy_Universe\", range = (0, 3), functions = { \"Small\": { \"type\": \"LinearZ\", \"parameters\": { \"shoulder\": 0, \"foot\": 2 } }, \"Medium\": { \"type\": \"Gauss\", \"parameters\": { \"mean\": 1.5, \"std\": 1 } }, \"Big\": { \"type\": \"LinearS\", \"parameters\": { \"foot\": 1, \"shoulder\": 3 } } } ) It is up to you how to do it, but the first option is prefered, as it will allow us to save all the parameters into a json that is separate from the main code, to help us abstract the parameter setting phase from the model instancing and training.\nNext we need to create the input tensor, in this case must have 3 dimensions, as by design a universe will only accept batched tensors.\nx = torch.linspace(0, 3, 9).unsqueeze(0).unsqueeze(-1) f_x = universe(x) The input tensor x will be:\ntensor([[[0.0000], [0.3750], [0.7500], [1.1250], [1.5000], [1.8750], [2.2500], [2.6250], [3.0000]]]) And the output tensor f_x will be:\ntensor([[[1.0000, 0.3247, 0.0000], [0.8125, 0.5311, 0.0000], [0.6250, 0.7548, 0.0000], [0.4375, 0.9321, 0.0625], [0.2500, 1.0000, 0.2500], [0.0625, 0.9321, 0.4375], [0.0000, 0.7548, 0.6250], [0.0000, 0.5311, 0.8125], [0.0000, 0.3247, 1.0000]]], grad_fn=\u003cCatBackward0\u003e) As expected, each input has been parsed through each of the 3 functions of the universe to give back a tensor of dimension (1, 9, 3)\nVisualisation To visualize a function we will import the function and the matplotlib module:\nimport matplotlib.pyplot as plt import torch from pyanfis.functions import Universe Before plotting it, we will need the x values given by x and the y value given by f_x:\nuniverse = Universe(**params) x = torch.linspace(0, 3, 9).unsqueeze(0).unsqueeze(-1) f_x = universe(x) To plot the image use:\nplt.style.use(\"classic\") plt.title(universe.name) plt.xlabel(\"x\") plt.ylabel(\"f (x)\") plt.margins(y=0.05) for i in f_x[0,:,:].T: plt.plot(x[0, :, 0].detach(), i.detach()) plt.show() And the final plotted function will be:",
    "description": "CLASS pyanfis.functions.Universe(name, range, functions) Parameters name type description name str name of the universe range tuple range of the universe, from min to max where min \u003c max functions dict dict with names of functions and properties of functions In regards to the functions parameter, you should input a dictionary where each key is the name of the function and each value is a dict that indicates its type and and its parameters:",
    "tags": [],
    "title": "Universe",
    "uri": "/documentation/universe/index.html"
  },
  {
    "breadcrumb": "ANFIS",
    "content": "",
    "description": "",
    "tags": [],
    "title": "Categories",
    "uri": "/categories/index.html"
  },
  {
    "breadcrumb": "ANFIS",
    "content": "",
    "description": "",
    "tags": [],
    "title": "Tags",
    "uri": "/tags/index.html"
  }
]
